@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@book{cangelosi2015developmental,
  title={Developmental robotics: From babies to robots},
  author={Cangelosi, Angelo and Schlesinger, Matthew},
  year={2015},
  publisher={MIT press}
}

@article{linke2019adapting,
  title={Adapting behaviour via intrinsic reward: A survey and empirical study},
  author={Linke, Cam and Ady, Nadia M and White, Martha and Degris, Thomas and White, Adam},
  journal={arXiv preprint arXiv:1906.07865},
  year={2019}
}


@inproceedings{chitnis2020glib,
  title={GLIB: Efficient Exploration for Relational Model-Based Reinforcement Learning via Goal-Literal Babbling},
  author={Chitnis, Rohan and Silver, Tom and Tenenbaum, Josh and Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle={AAAI},
  year={2021}
}

@article{asada2009cognitive,
  title={Cognitive developmental robotics: A survey},
  author={Asada, Minoru and Hosoda, Koh and Kuniyoshi, Yasuo and Ishiguro, Hiroshi and Inui, Toshio and Yoshikawa, Yuichiro and Ogino, Masaki and Yoshida, Chisato},
  journal={IEEE transactions on autonomous mental development},
  volume={1},
  number={1},
  pages={12--34},
  year={2009},
  publisher={IEEE}
}

@article{oudeyer2007intrinsic,
  title={What is intrinsic motivation? A typology of computational approaches},
  author={Oudeyer, Pierre-Yves and Kaplan, Frederic},
  journal={Frontiers in neurorobotics},
  volume={1},
  pages={6},
  year={2007},
  publisher={Frontiers}
}

@inproceedings{baranesproximo,
  title={Proximo-Distal Competence Based Curiosity-Driven Exploration},
  author={Baranes, Adrien and Oudeyer, Pierre-Yves},
  booktitle={Learning, in" International Conference on Epigenetic Robotics, Italie},
  organization={Citeseer},
  year={2009}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{bellemare2020autonomous,
  title={Autonomous navigation of stratospheric balloons using reinforcement learning},
  author={Bellemare, Marc G and Candido, Salvatore and Castro, Pablo Samuel and Gong, Jun and Machado, Marlos C and Moitra, Subhodeep and Ponda, Sameera S and Wang, Ziyu},
  journal={Nature},
  volume={588},
  number={7836},
  pages={77--82},
  year={2020},
  publisher={Nature Publishing Group}
}


@article{achiam2017surprise,
  title={Surprise-based intrinsic motivation for deep reinforcement learning},
  author={Achiam, Joshua and Sastry, Shankar},
  journal={arXiv preprint arXiv:1703.01732},
  year={2017},
}

@article{berseth2019smirl,
  title={SMiRL: Surprise Minimizing RL in Dynamic Environments},
  author={Berseth, Glen and Geng, Daniel and Devin, Coline and Finn, Chelsea and Jayaraman, Dinesh and Levine, Sergey},
  journal={arXiv preprint arXiv:1912.05510},
  year={2019}
}

@article{sekar2020planning,
  title={Planning to Explore via Self-Supervised World Models},
  author={Sekar, Ramanan and Rybkin, Oleh and Daniilidis, Kostas and Abbeel, Pieter and Hafner, Danijar and Pathak, Deepak},
  journal={arXiv preprint arXiv:2005.05960},
  year={2020}
}


@inproceedings{schmidhuber1991possibility,
  title={A possibility for implementing curiosity and boredom in model-building neural controllers},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proc. of the international conference on simulation of adaptive behavior: From animals to animats},
  pages={222--227},
  year={1991}
}


@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}



@article{colas2020epidemioptim,
  title={EpidemiOptim: A Toolbox for the Optimization of Control Policies in Epidemiological Models},
  author={Colas, C{\'e}dric and Hejblum, Boris and Rouillon, S{\'e}bastien and Thi{\'e}baut, Rodolphe and Oudeyer, Pierre-Yves and Moulin-Frier, Cl{\'e}ment and Prague, M{\'e}lanie},
  journal={arXiv preprint arXiv:2010.04452},
  year={2020}
}

@inproceedings{lehman2011evolving,
  title={Evolving a diversity of virtual creatures through novelty search and local competition},
  author={Lehman, Joel and Stanley, Kenneth O},
  booktitle={Proceedings of the 13th annual conference on Genetic and evolutionary computation},
  pages={211--218},
  year={2011}
}

@article{santucci2016grail,
  title={GRAIL: a goal-discovering robotic architecture for intrinsically-motivated learning},
  author={Santucci, Vieri Giuliano and Baldassarre, Gianluca and Mirolli, Marco},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  volume={8},
  number={3},
  pages={214--231},
  year={2016},
  publisher={IEEE}
}

@article{martius2013information,
  title={Information driven self-organization of complex robotic behaviors},
  author={Martius, Georg and Der, Ralf and Ay, Nihat},
  journal={PloS one},
  volume={8},
  number={5},
  pages={e63400},
  year={2013},
  publisher={Public Library of Science}
}

@inproceedings{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@article{santucci2020intrinsically,
  title={Intrinsically motivated open-ended learning in autonomous robots},
  author={Santucci, Vieri Giuliano and Oudeyer, Pierre-Yves and Barto, Andrew and Baldassarre, Gianluca},
  journal={Frontiers in Neurorobotics},
  volume={13},
  pages={115},
  year={2020},
  publisher={Frontiers}
}

@article{imgep,
  title={Intrinsically motivated goal exploration processes with automatic curriculum learning},
  author={Forestier, S{\'e}bastien and Portelas, R{\'e}my and Mollard, Yoan and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:1708.02190},
  year={2017}
}

@article{mouret2015illuminating,
  title={Illuminating search spaces by mapping elites},
  author={Mouret, Jean-Baptiste and Clune, Jeff},
  journal={arXiv preprint arXiv:1504.04909},
  year={2015}
}

@inproceedings{colas2020scaling,
  title={Scaling MAP-Elites to deep neuroevolution},
  author={Colas, C{\'e}dric and Madhavan, Vashisht and Huizinga, Joost and Clune, Jeff},
  booktitle={Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
  pages={67--75},
  year={2020}
}

@article{doncieux2018open,
  title={Open-ended Learning: a Conceptual Framework based on Representational Redescription},
  author={Doncieux, Stephane and Filliat, David and D{\'\i}az-Rodr{\'\i}guez, Natalia and Hospedales, Timothy  and Duro, Richard and Coninx, Alexandre and Roijers, Diederik M. and Girard, Beno\^{i}t and Perrin, Nicolas and Sigaud, Olivier},
  journal={Frontiers in Robotics and AI},
  volume={12},
  publisher={Frontiers Media SA},
  doi={10.3389/fnbot.2018.00059},
  year={2018}
}


@article{yuan2019interactive,
  title={Interactive language learning by question answering},
  author={Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Fu, Jie and Lin, Zhouhan and Pal, Christopher and Bengio, Yoshua and Trischler, Adam},
  journal={arXiv preprint arXiv:1908.10909},
  year={2019}
}


@book{gopnik1999scientist,
  title={The scientist in the crib: Minds, brains, and how children learn.},
  author={Gopnik, Alison and Meltzoff, Andrew N and Kuhl, Patricia K},
  year={1999},
  publisher={William Morrow \& Co}
}

@article{berlyne1966curiosity,
  title={Curiosity and exploration},
  author={Berlyne, Daniel E},
  journal={Science},
  volume={153},
  number={3731},
  pages={25--33},
  year={1966},
  publisher={JSTOR}
}


@article{gottlieb2018towards,
  title={Towards a neuroscience of active sampling and curiosity},
  author={Gottlieb, Jacqueline and Oudeyer, Pierre-Yves},
  journal={Nature Reviews Neuroscience},
  volume={19},
  number={12},
  pages={758--770},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{Andreas_2016,
   title={Neural Module Networks},
   ISBN={9781467388511},
   url={http://dx.doi.org/10.1109/CVPR.2016.12},
   DOI={10.1109/cvpr.2016.12},
   journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
   year={2016},
   month={Jun}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International Conference on Machine Learning},
  pages={1312--1320},
  year={2015}
}
@misc{zaremba2014recurrent,
    title={Recurrent Neural Network Regularization},
    author={Wojciech Zaremba and Ilya Sutskever and Oriol Vinyals},
    year={2014},
    eprint={1409.2329},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@inproceedings{schmidhuber1991learning,
  title={Learning to generate sub-goals for action sequences},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Artificial neural networks},
  pages={967--972},
  year={1991}
}

@inproceedings{bacon2017option,
  title={The option-critic architecture},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}


@inproceedings{sutton1998intra,
  title={Intra-Option Learning about Temporally Abstract Actions.},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder P},
  booktitle={ICML},
  volume={98},
  pages={556--564},
  year={1998}
}


@article{campero2020learning,
  title={Learning with AMIGo: Adversarially Motivated Intrinsic Goals},
  author={Campero, Andres and Raileanu, Roberta and K{\"u}ttler, Heinrich and Tenenbaum, Joshua B and Rockt{\"a}schel, Tim and Grefenstette, Edward},
  journal={arXiv preprint arXiv:2006.12122},
  year={2020}
}


@article{ecoffet2020first,
  title={First return then explore},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:2004.12919},
  year={2020}
}

@inproceedings{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
  booktitle={Advances in neural information processing systems},
  pages={3675--3683},
  year={2016}
}

@article{vezhnevets2017feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1703.01161},
  year={2017}
}
@inproceedings{nachum2018data,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3303--3313},
  year={2018}
}

@article{roder2020curious,
  title={Curious Hierarchical Actor-Critic Reinforcement Learning},
  author={R{\"o}der, Frank and Eppe, Manfred and Nguyen, Phuong DH and Wermter, Stefan},
  journal={arXiv preprint arXiv:2005.03420},
  year={2020}
}

@phdthesis{precup2001temporal,
  title={Temporal abstraction in reinforcement learning},
  author={Precup, Doina},
  school={The University of Massachussetts},
  year={2000}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{dayan1993feudal,
  title={Feudal reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={271--278},
  year={1993}
}


@inproceedings{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14843--14854},
  year={2019}
}


@article{frans2017meta,
  title={Meta learning shared hierarchies},
  author={Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
  journal={arXiv preprint arXiv:1710.09767},
  year={2017}
}

@article{haarnoja2018latent,
  title={Latent space policies for hierarchical reinforcement learning},
  author={Haarnoja, Tuomas and Hartikainen, Kristian and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1804.02808},
  year={2018}
}

@misc{florensa2019selfsupervised,
    title={Self-supervised Learning of Image Embedding for Continuous Control},
    author={Carlos Florensa and Jonas Degrave and Nicolas Heess and Jost Tobias Springenberg and Martin Riedmiller},
    year={2019},
    eprint={1901.00943},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{baranes2009r,
  title={R-iac: Robust intrinsically motivated exploration and active learning},
  author={Baranes, Adrien and Oudeyer, Pierre-Yves},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={1},
  number={3},
  pages={155--169},
  year={2009},
  publisher={IEEE}
}


@article{oudeyer2009intrinsic,
  title={What is intrinsic motivation? A typology of computational approaches},
  author={Oudeyer, Pierre-Yves and Kaplan, Frederic},
  journal={Frontiers in neurorobotics},
  volume={1},
  pages={6},
  year={2009},
  publisher={Frontiers}
}

@book{sutton2009ambiguity,
  title={The ambiguity of play},
  author={Sutton-Smith, Brian},
  year={2009},
  publisher={Harvard University Press}
}


@book{montessori2013montessori,
  title={The Montessori Method},
  author={Montessori, Maria},
  year={2013},
  publisher={Transaction publishers}
}

@book{piaget1955construction,
  title={The construction of reality in the child},
  author={Piaget, Jean},
  volume={82},
  year={1955},
  publisher={Routledge}
}


@article{chu2020exploratory,
  title={Exploratory play, rational action, and efficient search},
  author={Chu, Junyi and Schulz, Laura},
  year={2020},
  journal={PsyArXiv}
}


@article{du2019compositional,
  title={Compositional Visual Generation with Energy Based Models},
  author={Du, Yilun and Li, Shuang and Mordatch, Igor},
  journal={submitted to ICLR},
  year={2019}
}

@article{fikes1971strips,
  title={STRIPS: A new approach to the application of theorem proving to problem solving},
  author={Fikes, Richard E and Nilsson, Nils J},
  journal={Artificial intelligence},
  volume={2},
  number={3-4},
  pages={189--208},
  year={1971},
  publisher={Elsevier}
}

@article{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1707.05300},
  year={2017}
}


@article{zhang2020automatic,
  title={Automatic curriculum learning through value disagreement},
  author={Zhang, Yunzhi and Abbeel, Pieter and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2006.09641},
  year={2020}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in neural information processing systems},
  pages={4565--4573},
  year={2016}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and M\"{u}ller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@article{oh2017zero,
  title={Zero-shot task generalization with multi-task deep reinforcement learning},
  author={Oh, Junhyuk and Singh, Satinder and Lee, Honglak and Kohli, Pushmeet},
  journal={arXiv preprint arXiv:1706.05064},
  year={2017}
}


@incollection{ding_imitation_2019,
title = {Goal-conditioned Imitation Learning},
author = {Ding, Yiming and Florensa, Carlos and Abbeel, Pieter and Phielipp, Mariano},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d'Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {15324--15335},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9667-goal-conditioned-imitation-learning.pdf}
}


@InProceedings{pmlr-v100-lynch20a,
  title =      {Learning Latent Plans from Play},
  author =      {Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  booktitle =      {Proceedings of the Conference on Robot Learning},
  pages =      {1113--1132},
  year =      {2020},
  editor =      {Kaelbling, Leslie Pack and Kragic, Danica and Sugiura, Komei},
  volume =      {100},
  series =      {Proceedings of Machine Learning Research},
  address =      {},
  month =      {30 Oct--01 Nov},
  publisher =      {PMLR},
  pdf =      {http://proceedings.mlr.press/v100/lynch20a/lynch20a.pdf},
  url =      {http://proceedings.mlr.press/v100/lynch20a.html},
}

@article{charlesworth2020plangan,
  title={PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals},
  author={Charlesworth, Henry and Montana, Giovanni},
  journal={arXiv preprint arXiv:2006.00900},
  year={2020}
}

@article{eysenbach2020rewriting,
  title={Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement},
  author={Eysenbach, Benjamin and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2002.11089},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={5998--6008},
  year={2017}
}


@misc{kovac2020grimgep,
      title={GRIMGEP: Learning Progress for Robust Goal Sampling in Visual Deep Reinforcement Learning}, 
      author={Grgur Kovač and Adrien Laversanne-Finot and Pierre-Yves Oudeyer},
      year={2020},
      eprint={2008.04388},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{blaes2019control,
  title={Control what you can: Intrinsically motivated task-planning agent},
  author={Blaes, Sebastian and Vlastelica Pogan{\v{c}}i{\'c}, Marin and Zhu, Jiajie and Martius, Georg},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={12541--12552},
  year={2019}
}

@article{fournier2019clic,
  title={CLIC: Curriculum Learning and Imitation for object Control in non-rewarding environments},
  author={Fournier, Pierre and Colas, C{\'e}dric and Chetouani, Mohamed and Sigaud, Olivier},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  year={2019},
  publisher={IEEE}
}



@misc{gregor2016variational,
      title={Variational Intrinsic Control}, 
      author={Karol Gregor and Danilo Jimenez Rezende and Daan Wierstra},
      year={2016},
      eprint={1611.07507},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wu2018laplacian,
      title={The Laplacian in RL: Learning Representations with Efficient Approximations}, 
      author={Yifan Wu and George Tucker and Ofir Nachum},
      year={2018},
      eprint={1810.04586},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{goodfellow2014generative,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}  

@inproceedings{zhu2017target,
  title={Target-driven visual navigation in indoor scenes using deep reinforcement learning},
  author={Zhu, Yuke and Mottaghi, Roozbeh and Kolve, Eric and Lim, Joseph J and Gupta, Abhinav and Fei-Fei, Li and Farhadi, Ali},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3357--3364},
  year={2017},
  organization={IEEE}
}


@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@article{li2019towards,
  title={Towards Practical Multi-Object Manipulation using Relational Reinforcement Learning},
  author={Li, Richard and Jabri, Allan and Darrell, Trevor and Agrawal, Pulkit},
  journal={arXiv preprint arXiv:1912.11032},
  year={2019}
}

@misc{loynd2019working,
    title={Working Memory Graphs},
    author={Ricky Loynd and Roland Fernandez and Asli Celikyilmaz and Adith Swaminathan and Matthew Hausknecht},
    year={2019},
    eprint={1911.07141},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{akakzia2020decstr,
  title={{DECSTR}: Learning Goal-Directed Abstract Behaviors using Pre-Verbal Spatial Predicates in Intrinsically Motivated Agents},
  author={Akakzia, Ahmed and Colas, C{\'e}dric and Oudeyer, Pierre-Yves and Chetouani, Mohamed and Sigaud, Olivier},
  journal={arXiv preprint arXiv:2006.07185},
  year={2020}
}

@article{badia2020never,
  title={Never Give Up: Learning Directed Exploration Strategies},
  author={Badia, Adri{\`a} Puigdom{\`e}nech and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Piot, Bilal and Kapturowski, Steven and Tieleman, Olivier and Arjovsky, Mart{\'\i}n and Pritzel, Alexander and Bolt, Andew and others},
  journal={arXiv preprint arXiv:2002.06038},
  year={2020}
}


@book{phares1988introduction,
  title={Introduction to personality},
  author={Phares, E Jerry},
  year={1988},
  publisher={Scott, Foresman \& Co}
}

@book{nicomachean,
  title={The Nicomachean Ethics},
  author={Aristotle},
  year={-0350},
  publisher = {Penguin Books}
}

@book{ram1995goal,
  title={Goal-driven learning},
  author={Ram, Ashwin and Leake, David B and Leake, David},
  year={1995},
  publisher={MIT press}
}


@incollection{heckhausen1985wishes,
  title={From wishes to action: The dead ends and short cuts on the long way to action},
  author={Heckhausen, Heinz and Kuhl, Julius},
  booktitle={ED Goal directed behavior: The concept of action in psychology},
  pages={134--159},
  year={1985},
  publisher={Erlbaum}
}

@article{elliot2008goal,
  title={The goal construct in psychology},
  author={Elliot, Andrew J and Fryer, James W},
  journal={Handbook of motivation science},
  volume={18},
  pages={235--250},
  year={2008}
}

@article{mitchell1982motivation,
  title={Motivation: New directions for theory, research, and practice},
  author={Mitchell, Terence R},
  journal={Academy of management review},
  volume={7},
  number={1},
  pages={80--88},
  year={1982},
  publisher={Academy of Management Briarcliff Manor, NY 10510}
}

@article{badia2020agent57,
  title={Agent57: Outperforming the atari human benchmark},
  author={Badia, Adri{\`a} Puigdom{\`e}nech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Blundell, Charles},
  journal={arXiv preprint arXiv:2003.13350},
  year={2020}
}

@article{tasse2020boolean,
  title={A Boolean Task Algebra for Reinforcement Learning},
  author={Tasse, Geraud Nangue and James, Steven and Rosman, Benjamin},
  journal={arXiv preprint arXiv:2001.01394},
  year={2020}
}

@article{taylor2009transfer,
  title={Transfer learning for reinforcement learning domains: A survey.},
  author={Taylor, Matthew E and Stone, Peter},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={7},
  year={2009}
}

@inproceedings{das2018embodied,
  title={Embodied question answering},
  author={Das, Abhishek and Datta, Samyak and Gkioxari, Georgia and Lee, Stefan and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={2054--2063},
  year={2018}
}


@article{cideron2020qd,
  title={QD-RL: Efficient Mixing of Quality and Diversity in Reinforcement Learning},
  author={Cideron, Geoffrey and Pierrot, Thomas and Perrin, Nicolas and Beguir, Karim and Sigaud, Olivier},
  journal={arXiv preprint arXiv:2006.08505},
  year={2020}
}

@article{colas2020language,
  title={Language-Conditioned Goal Generation: a New Approach to Language Grounding for RL},
  author={Colas, C{\'e}dric and Akakzia, Ahmed and Oudeyer, Pierre-Yves and Chetouani, Mohamed and Sigaud, Olivier},
  journal={arXiv preprint arXiv:2006.07043},
  year={2020}
}

@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}


@article{pitis2020maximum,
  title={Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning},
  author={Pitis, Silviu and Chan, Harris and Zhao, Stephen and Stadie, Bradly and Ba, Jimmy},
  journal={arXiv preprint arXiv:2007.02832},
  year={2020}
}

@article{lynch2020grounding,
  title={Grounding Language in Play},
  author={Lynch, Corey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:2005.07648},
  year={2020}
}


@article{sukhbaatar2017intrinsic,
  title={Intrinsic motivation and automatic curricula via asymmetric self-play},
  author={Sukhbaatar, Sainbayar and Lin, Zeming and Kostrikov, Ilya and Synnaeve, Gabriel and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1703.05407},
  year={2017}
}


@inproceedings{sutton2011horde,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 2},
  pages={761--768},
  year={2011}
}

@article{Yuan_2019,
   title={Interactive Language Learning by Question Answering},
   url={http://dx.doi.org/10.18653/v1/D19-1280},
   DOI={10.18653/v1/d19-1280},
   journal={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
   publisher={Association for Computational Linguistics},
   author={Yuan, Xingdi and Côté, Marc-Alexandre and Fu, Jie and Lin, Zhouhan and Pal, Chris and Bengio, Yoshua and Trischler, Adam},
   year={2019}
}

@inproceedings{rolf2015goals,
  title={What are goals? And if so, how many?},
  author={Rolf, Matthias and Asada, Minoru},
  booktitle={2015 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)},
  pages={332--339},
  year={2015},
  organization={IEEE}
}

@article{lanier2019curiosity,
  author    = {John B. Lanier and Stephen McAleer and Pierre Baldi},
  title     = {Curiosity-Driven Multi-Criteria Hindsight Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1906.03710},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.03710},
  archivePrefix = {arXiv},
  eprint    = {1906.03710},
  timestamp = {Fri, 14 Jun 2019 09:38:24 +0200}
}

@inproceedings{nair2020contextual,
  title={Contextual imagined goals for self-supervised robotic learning},
  author={Nair, Ashvin and Bahl, Shikhar and Khazatsky, Alexander and Pong, Vitchyr and Berseth, Glen and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={530--539},
  year={2020}
}

@misc{coreyes2018guiding,
    title={Guiding Policies with Language via Meta-Learning},
    author={John D. Co-Reyes and Abhishek Gupta and Suvansh Sanjeev and Nick Altieri and Jacob Andreas and John DeNero and Pieter Abbeel and Sergey Levine},
    year={2018},
    eprint={1811.07882},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{venkattaramanujam2019self,
  title={Self-supervised Learning of Distance Functions for Goal-Conditioned Reinforcement Learning},
  author={Venkattaramanujam, Srinivas and Crawford, Eric and Doan, Thang and Precup, Doina},
  journal={arXiv preprint arXiv:1907.02998},
  year={2019}
}

@misc{chan2019actrce,
    title={ACTRCE: Augmenting Experience via Teacher's Advice For Multi-Goal Reinforcement Learning},
    author={Harris Chan and Yuhuai Wu and Jamie Kiros and Sanja Fidler and Jimmy Ba},
    year={2019},
    eprint={1902.04546},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{goldberg2003constructions,
  title={Constructions: A new theoretical approach to language},
  author={Goldberg, Adele E},
  journal={Trends in cognitive sciences},
  volume={7},
  number={5},
  pages={219--224},
  year={2003},
  publisher={Elsevier}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}


@article{collobert2011natural,
  title={Natural language processing (almost) from scratch},
  author={Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journal={Journal of machine learning research},
  volume={12},
  number={Aug},
  pages={2493--2537},
  year={2011}
}


@article{hinaut2013real,
  title={Real-time parallel processing of grammatical structure in the fronto-striatal system: A recurrent network simulation study using reservoir computing},
  author={Hinaut, Xavier and Dominey, Peter Ford},
  journal={PloS one},
  volume={8},
  number={2},
  year={2013},
  publisher={Public Library of Science}
}

@article{tomasello2000item,
  title={The item-based nature of children’s early syntactic development},
  author={Tomasello, Michael},
  journal={Trends in cognitive sciences},
  volume={4},
  number={4},
  pages={156--163},
  year={2000},
  publisher={Elsevier}
}

@article{tomasello1993twenty,
  title={Twenty-three-month-old children have a grammatical category of noun},
  author={Tomasello, Michael and Olguin, Raquel},
  journal={Cognitive development},
  volume={8},
  number={4},
  pages={451--464},
  year={1993},
  publisher={Elsevier}
}

@article{mintz2003frequent,
  title={Frequent frames as a cue for grammatical categories in child directed speech},
  author={Mintz, Toben H},
  journal={Cognition},
  volume={90},
  number={1},
  pages={91--117},
  year={2003},
  publisher={Elsevier}
}


@article{spelke1992origins,
  title={Origins of knowledge.},
  author={Spelke, Elizabeth S and Breinlinger, Karen and Macomber, Janet and Jacobson, Kristen},
  journal={Psychological review},
  volume={99},
  number={4},
  pages={605},
  year={1992},
  publisher={American Psychological Association}
}


@article{johnson2003development,
  title={Development of object concepts in infancy: Evidence for early learning in an eye-tracking paradigm},
  author={Johnson, Scott P and Amso, Dima and Slemmer, Jonathan A},
  journal={Proceedings of the National Academy of Sciences},
  volume={100},
  number={18},
  pages={10568--10573},
  year={2003},
  publisher={National Acad Sciences}
}


@article{hochreiter1997lstm,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@article{mcclelland2019extending,
  title={Extending Machine Language Models toward Human-Level Language Understanding},
  author={McClelland, James L and Hill, Felix and Rudolph, Maja and Baldridge, Jason and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:1912.05877},
  year={2019}
}

@article{johnson2013object,
  title={Object perception},
  author={Johnson, Scott P},
  journal={Handbook of developmental psychology},
  pages={371--379},
  year={2013}
}

@article{green2017object,
  title={What is an object file?},
  author={Green, Edwin James and Quilty-Dunn, Jake},
  journal={The British Journal for the Philosophy of Science},
  year={2017}
}

@article{burgess2019monet,
  title={Monet: Unsupervised scene decomposition and representation},
  author={Burgess, Christopher P and Matthey, Loic and Watters, Nicholas and Kabra, Rishabh and Higgins, Irina and Botvinick, Matt and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1901.11390},
  year={2019}
}

@article{greff2019multi,
  title={Multi-object representation learning with iterative variational inference},
  author={Greff, Klaus and Kaufmann, Rapha{\"e}l Lopez and Kabra, Rishab and Watters, Nick and Burgess, Chris and Zoran, Daniel and Matthey, Loic and Botvinick, Matthew and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1903.00450},
  year={2019}
}



@article{wagstaff2019limitations,
  title={On the limitations of representing functions on sets},
  author={Wagstaff, Edward and Fuchs, Fabian B and Engelcke, Martin and Posner, Ingmar and Osborne, Michael},
  journal={arXiv preprint arXiv:1901.09006},
  year={2019}
}


@book{baldassarre2013intrinsically,
  title={Intrinsically motivated learning in natural and artificial systems},
  author={Baldassarre, Gianluca and Mirolli, Marco},
  year={2013},
  publisher={Springer}
}

@article{pong2019skew,
  title={Skew-fit: State-covering self-supervised reinforcement learning},
  author={Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  journal={arXiv preprint arXiv:1903.03698},
  year={2019}
}

@inproceedings{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9191--9200},
  year={2018}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={16--17},
  year={2017}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in neural information processing systems},
  pages={1471--1479},
  year={2016}
}

@article{kidd2015psychology,
  title={The psychology and neuroscience of curiosity},
  author={Kidd, Celeste and Hayden, Benjamin Y},
  journal={Neuron},
  volume={88},
  number={3},
  pages={449--460},
  year={2015},
  publisher={Elsevier}
}

@article{kaplan2007search,
  title={In search of the neural circuits of intrinsic motivation},
  author={Kaplan, Frederic and Oudeyer, Pierre-Yves},
  journal={Frontiers in neuroscience},
  volume={1},
  pages={17},
  year={2007},
  publisher={Frontiers}
}

@article{laversanne2018curiosity,
  title={Curiosity driven exploration of learned disentangled goal spaces},
  author={Laversanne-Finot, Adrien and P{\'e}r{\'e}, Alexandre and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:1807.01521},
  year={2018}
}

  

@misc{chaplot2017gatedattention,
    title={Gated-Attention Architectures for Task-Oriented Language Grounding},
    author={Devendra Singh Chaplot and Kanthashree Mysore Sathyendra and Rama Kumar Pasumarthi and Dheeraj Rajagopal and Ruslan Salakhutdinov},
    year={2017},
    eprint={1706.07230},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{colas2019hitchhiker,
  title={A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms},
  author={Colas, C{\'e}dric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:1904.06979},
  year={2019}
}


@inproceedings{he,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}


@misc{bahdanau2018systematic,
    title={Systematic Generalization: What Is Required and Can It Be Learned?},
    author={Dzmitry Bahdanau and Shikhar Murty and Michael Noukhovitch and Thien Huu Nguyen and Harm de Vries and Aaron Courville},
    year={2018},
    eprint={1811.12889},
    archivePrefix={arXiv},
    primaryClass={cs.CL}}

@misc{hill2019emergent,
    title={Emergent Systematic Generalization in a Situated Agent},
    author={Felix Hill and Andrew Lampinen and Rosalia Schneider and Stephen Clark and Matthew Botvinick and James L. McClelland and Adam Santoro},
    year={2019},
    eprint={1910.00571},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@article{pugh2016quality,
  title={Quality diversity: A new frontier for evolutionary computation},
  author={Pugh, Justin K. and Soros, Lisa B. and Stanley, Kenneth O.},
  journal={Frontiers in Robotics and AI},
  volume={3},
  pages={40},
  year={2016},
  publisher={Frontiers}
}

@inproceedings{deepset,
  title={Deep sets},
  author={Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Russ R and Smola, Alexander J},
  booktitle={Advances in neural information processing systems},
  pages={3391--3401},
  year={2017}
}



@article{steels2006semiotic,
  title={Semiotic dynamics for embodied agents},
  author={Steels, Luc},
  journal={IEEE Intelligent Systems},
  volume={21},
  number={3},
  pages={32--38},
  year={2006},
  publisher={IEEE}
}

@article{pugh2016quality,
  title={Quality diversity: A new frontier for evolutionary computation},
  author={Pugh, Justin K and Soros, Lisa B and Stanley, Kenneth O},
  journal={Frontiers in Robotics and AI},
  volume={3},
  pages={40},
  year={2016},
  publisher={Frontiers}
}




@article{plappert2018multi,
  title={Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research},
  author={Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and McGrew, Bob and Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and others},
  journal={arXiv preprint arXiv:1802.09464},
  year={2018}
}

@article{fujimoto2018addressing,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, Dave},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{DBLP:journals/tnn/SuttonB98,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement Learning: An Introduction},
  journal   = {{IEEE} Trans. Neural Networks},
  volume    = {9},
  number    = {5},
  pages     = {1054--1054},
  year      = {1998},
  url       = {https://doi.org/10.1109/TNN.1998.712192},
  doi       = {10.1109/TNN.1998.712192},
  timestamp = {Sun, 28 May 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/tnn/SuttonB98},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}


@misc{ruis2020benchmark,
      title={A Benchmark for Systematic Generalization in Grounded Language Understanding}, 
      author={Laura Ruis and Jacob Andreas and Marco Baroni and Diane Bouchacourt and Brenden M. Lake},
      year={2020},
      eprint={2003.05161},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}




@article{mankowitz2018unicorn,
  title={Unicorn: Continual Learning with a Universal, Off-policy Agent},
  author={Mankowitz, Daniel J and {\v{Z}}{\'\i}dek, Augustin and Barreto, Andr{\'e} and Horgan, Dan and Hessel, Matteo and Quan, John and Oh, Junhyuk and van Hasselt, Hado and Silver, David and Schaul, Tom},
  journal={arXiv preprint arXiv:1802.08294},
  year={2018}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{forestier2016modular,
  title={Modular active curiosity-driven discovery of tool use},
  author={Forestier, S{\'e}bastien and Oudeyer, Pierre-Yves},
  booktitle={Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on},
  pages={3965--3972},
  year={2016},
  organization={IEEE}
}

@article{riedmiller2018learning,
  title={Learning by Playing-Solving Sparse Reward Tasks from Scratch},
  author={Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and Van de Wiele, Tom and Mnih, Volodymyr and Heess, Nicolas and Springenberg, Jost Tobias},
  journal={arXiv preprint arXiv:1802.10567},
  year={2018}
}


@incollection{kaplan2004maximizing,
  title={Maximizing learning progress: an internal reward system for development},
  author={Kaplan, Fr{\'e}d{\'e}ric and Oudeyer, Pierre-Yves},
  booktitle={Embodied artificial intelligence},
  pages={259--270},
  year={2004},
  publisher={Springer}
}

@article{oudeyer2016evolution,
  title={How evolution may work through curiosity-driven developmental process},
  author={Oudeyer, Pierre-Yves and Smith, Linda B},
  journal={Topics in Cognitive Science},
  volume={8},
  number={2},
  pages={492--502},
  year={2016},
  publisher={Wiley Online Library}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@article{rolf2010goal,
  title={Goal babbling permits direct learning of inverse kinematics},
  author={Rolf, Matthias and Steil, Jochen J and Gienger, Michael},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={3},
  pages={216--229},
  year={2010},
  publisher={IEEE}
}

@inproceedings{baranes2011interaction,
  title={The interaction of maturational constraints and intrinsic motivations in active motor development},
  author={Baranes, Adrien and Oudeyer, Pierre-Yves},
  booktitle={Development and Learning (ICDL), 2011 IEEE International Conference on},
  volume={2},
  pages={1--8},
  year={2011},
  organization={IEEE}
}

@article{fournier2018accuracy,
  title={Accuracy-based curriculum learning in deep reinforcement learning},
  author={Fournier, Pierre and Sigaud, Olivier and Chetouani, Mohamed and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:1806.09614},
  year={2018}
}


@inproceedings{baranes2010intrinsically,
  title={Intrinsically motivated goal exploration for active motor learning in robots: A case study},
  author={Baranes, Adrien and Oudeyer, Pierre-Yves},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010)},
  year={2010}
}

@article{baranes2013active,
  title={Active learning of inverse models with intrinsically motivated goal exploration in robots},
  author={Baranes, Adrien and Oudeyer, Pierre-Yves},
  journal={Robotics and Autonomous Systems},
  volume={61},
  number={1},
  pages={49--73},
  year={2013},
  publisher={Elsevier}
}

@article{forestier2017intrinsically,
  title={Intrinsically motivated goal exploration processes with automatic curriculum learning},
  author={Forestier, S{\'e}bastien and Mollard, Yoan and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:1708.02190},
  year={2017}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{colas2018gep,
  title={{GEP-PG}: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms},
  author={Colas, C{\'e}dric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:1802.05054},
  year={2018}
}

@article{nair2017overcoming,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1709.10089},
  year={2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}


@article{Luketina2019,
abstract = {To be successful in real-world tasks, Reinforcement Learning (RL) needs to exploit the compositional, relational, and hierarchical structure of the world, and learn to transfer it to the task at hand. Recent advances in representation learning for language make it possible to build models that acquire world knowledge from text corpora and integrate this knowledge into downstream decision making problems. We thus argue that the time is right to investigate a tight integration of natural language understanding into RL in particular. We survey the state of the field, including work on instruction following, text games, and learning from textual domain knowledge. Finally, we call for the development of new environments as well as further investigation into the potential uses of recent Natural Language Processing (NLP) techniques for such tasks.},
archivePrefix = {arXiv},
arxivId = {1906.03926},
author = {Luketina, Jelena and Nardelli, Nantas and Farquhar, Gregory and Foerster, Jakob and Andreas, Jacob and Grefenstette, Edward and Whiteson, Shimon and Rockt{\"{a}}schel, Tim},
eprint = {1906.03926},
journal = {IJCAI'19},
mendeley-groups = {Review IML},
month = {jun},
title = {{A Survey of Reinforcement Learning Informed by Natural Language}},
url = {http://arxiv.org/abs/1906.03926},
year = {2019}
}

@inproceedings{bahdanau2018learning,
abstract = {Recent work has shown that deep reinforcement-learning agents can learn to follow language-like instructions from infrequent environment rewards. However, this places on environment designers the onus of designing language-conditional reward functions which may not be easily or tractably implemented as the complexity of the environment and the language scales. To overcome this limitation, we present a framework within which instruction-conditional RL agents are trained using rewards obtained not from the environment, but from reward models which are jointly trained from expert examples. As reward models improve, they learn to accurately reward agents for completing tasks for environment configurations---and for instructions---not present amongst the expert data. This framework effectively separates the representation of what instructions require from how they can be executed. In a simple grid world, it enables an agent to learn a range of commands requiring interaction with blocks and understanding of spatial relations and underspecified abstract arrangements. We further show the method allows our agent to adapt to changes in the environment without requiring new expert examples.},
archivePrefix = {arXiv},
arxivId = {1806.01946},
author = {Bahdanau, Dzmitry and Hill, Felix and Leike, Jan and Hughes, Edward and Kohli, Pushmeet and Grefenstette, Edward},
booktitle = {International Conference on Learning Representations},
eprint = {1806.01946},
month = {jun},
title = {{Learning to Understand Goal Specifications by Modelling Reward}},
year = {2019}
}

@inproceedings{Jiang2019,
abstract = {Solving complex, temporally-extended tasks is a long-standing problem in reinforcement learning (RL). We hypothesize that one critical element of solving such problems is the notion of compositionality. With the ability to learn concepts and sub-skills that can be composed to solve longer tasks, i.e. hierarchical RL, we can acquire temporally-extended behaviors. However, acquiring effective yet general abstractions for hierarchical RL is remarkably challenging. In this paper, we propose to use language as the abstraction, as it provides unique compositional structure, enabling fast learning and combinatorial generalization, while retaining tremendous flexibility, making it suitable for a variety of problems. Our approach learns an instruction-following low-level policy and a high-level policy that can reuse abstractions across tasks, in essence, permitting agents to reason using structured language. To study compositional task learning, we introduce an open-source object interaction environment built using the MuJoCo physics engine and the CLEVR engine. We find that, using our approach, agents can learn to solve to diverse, temporally-extended tasks such as object sorting and multi-object rearrangement, including from raw pixel observations. Our analysis find that the compositional nature of language is critical for learning diverse sub-skills and systematically generalizing to new sub-skills in comparison to non-compositional abstractions that use the same supervision.},
archivePrefix = {arXiv},
arxivId = {1906.07343},
author = {Jiang, Yiding and Gu, Shixiang and Murphy, Kevin and Finn, Chelsea},
booktitle = { Workshop on “Structure {\&} Priors in Reinforcement Learning”at ICLR 2019},
eprint = {1906.07343},
month = {jun},
title = {{Language as an Abstraction for Hierarchical Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1906.07343},
year = {2019}
}

@misc{goyal2019recurrent,
    title={Recurrent Independent Mechanisms},
    author={Anirudh Goyal and Alex Lamb and Jordan Hoffmann and Shagun Sodhani and Sergey Levine and Yoshua Bengio and Bernhard Schölkopf},
    year={2019},
    eprint={1909.10893},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{Hermann2017,
abstract = {We are increasingly surrounded by artificially intelligent technology that takes decisions and executes actions on our behalf. This creates a pressing need for general means to communicate with, instruct and guide artificial agents, with human language the most compelling means for such communication. To achieve this in a scalable fashion, agents must be able to relate language to the world and to actions; that is, their understanding of language must be grounded and embodied. However, learning grounded language is a notoriously challenging problem in artificial intelligence research. Here we present an agent that learns to interpret language in a simulated 3D environment where it is rewarded for the successful execution of written instructions. Trained via a combination of reinforcement and unsupervised learning, and beginning with minimal prior knowledge, the agent learns to relate linguistic symbols to emergent perceptual representations of its physical surroundings and to pertinent sequences of actions. The agent's comprehension of language extends beyond its prior experience, enabling it to apply familiar language to unfamiliar situations and to interpret entirely novel instructions. Moreover, the speed with which this agent learns new words increases as its semantic knowledge grows. This facility for generalising and bootstrapping semantic knowledge indicates the potential of the present approach for reconciling ambiguous natural language with the complexity of the physical world.},
archivePrefix = {arXiv},
arxivId = {1706.06551},
author = {Hermann, Karl Moritz and Hill, Felix and Green, Simon and Wang, Fumin and Faulkner, Ryan and Soyer, Hubert and Szepesvari, David and Czarnecki, Wojciech Marian and Jaderberg, Max and Teplyashin, Denis and Wainwright, Marcus and Apps, Chris and Hassabis, Demis and Blunsom, Phil},
eprint = {1706.06551},
month = {jun},
title = {{Grounded Language Learning in a Simulated 3D World}},
url = {http://arxiv.org/abs/1706.06551},
year = {2017}
}
@inproceedings{Goyal2019,
abstract = {Recent reinforcement learning (RL) approaches have shown strong performance in complex domains such as Atari games, but are often highly sample inefficient. A common approach to reduce interaction time with the environment is to use reward shaping, which involves carefully designing reward functions that provide the agent intermediate rewards for progress towards the goal. However, designing appropriate shaping rewards is known to be difficult as well as time-consuming. In this work, we address this problem by using natural language instructions to perform reward shaping. We propose the LanguagE-Action Reward Network (LEARN), a framework that maps free-form natural language instructions to intermediate rewards based on actions taken by the agent. These intermediate language-based rewards can seamlessly be integrated into any standard reinforcement learning algorithm. We experiment with Montezuma's Revenge from the Atari Learning Environment, a popular benchmark in RL. Our experiments on a diverse set of 15 tasks demonstrate that, for the same number of interactions with the environment, language-based rewards lead to successful completion of the task 60{\%} more often on average, compared to learning without language.},
archivePrefix = {arXiv},
arxivId = {1903.02020},
author = {Goyal, Prasoon and Niekum, Scott and Mooney, Raymond J.},
booktitle = {IJCAI 2019},
eprint = {1903.02020},
month = {mar},
title = {{Using Natural Language for Reward Shaping in Reinforcement Learning}},
url = {http://arxiv.org/abs/1903.02020},
year = {2019}
}
@inproceedings{Chaplot2018,
abstract = {To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states.},
archivePrefix = {arXiv},
arxivId = {1706.07230},
author = {Chaplot, Devendra Singh and Sathyendra, Kanthashree Mysore and Pasumarthi, Rama Kumar and Rajagopal, Dheeraj and Salakhutdinov, Ruslan},
booktitle = {AAAI 2018},
eprint = {1706.07230},
month = {jun},
title = {{Gated-Attention Architectures for Task-Oriented Language Grounding}},
url = {http://arxiv.org/abs/1706.07230},
year = {2018}
}
@inproceedings{chevalier-boisvert2018babyai,
author = {Chevalier-Boisvert, Maxime and Bahdanau, Dzmitry and Lahlou, Salem and Willems, Lucas and Saharia, Chitwan and Nguyen, Thien Huu and Bengio, Yoshua},
booktitle = {International Conference on Learning Representations},
title = {{Baby{\{}AI{\}}: First Steps Towards Grounded Language Learning With a Human In the Loop}},
year = {2019}
}
@inproceedings{fu2018from,
author = {Fu, Justin and Korattikara, Anoop and Levine, Sergey and Guadarrama, Sergio},
booktitle = {International Conference on Learning Representations},
title = {{From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following}},
year = {2019}
}
@inproceedings{Branavan2010,
author = {{R. K. Branavan}, S and {S. Zettlemoyer}, Luke and Barzilay, Regina},
booktitle = {ACL 2010 - 48th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
pages = {1268--1277},
title = {{Reading Between the Lines: Learning to Map High-level Instructions to Commands}},
year = {2010}
}
@inproceedings{Chen2011,
author = {Chen, David L. and Mooney, Raymond J.},
booktitle = {AAAI Conference on Artificial Intelligence (AAAI), 2011 },
title = {{Learning to Interpret Natural Language Navigation Instructions from Observations}},
year = {2011}
}
@inproceedings{Kuhlmann04,
abstract = {We describe our current efforts towards creating a reinforcement learner that learns both from reinforcements provided by its environment and from human-generated advice. Our research involves two complementary components: (a) mapping advice expressed in English to a formal advice language and (b) using advice expressed in a formal notation in a reinforcement learner. We use a subtask of the challenging RoboCup simulated soccer task (Noda et al. 1998) as our testbed.},
author = "Kuhlmann, Gregory and Stone, Peter H and Mooney, Raymond J and Shavlik, Jude",
booktitle = {AAAI Workshop - Technical Report},
pages = {30--35},
title = {{Guiding a reinforcement learner with natural language advice: Initial results in RoboCup soccer}},
volume = {WS-04-10},
year = {2004}
}

@inproceedings{Silberer2012,
author = {Silberer, Carina and Lapata, Mirella},
booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
pages = {1423--1433},
publisher = {Association for Computational Linguistics},
title = {{Grounded Models of Semantic Representation}},
year = {2012}
}

@article{Zwaan05,
author = {Zwaan, Rolf and Madden, Carol},
doi = {10.1017/CBO9780511499968.010},
journal = {Grounding Cognition: The Role of Perception and Action in Memory, Language, and Thinking},
pages = {224--245},
publisher = {Cambridge University Press},
title = {{Embodied sentence comprehension}},
year = {2005}
}

@article{Glenberg2002,
author = {Glenberg, Arthur M. and Kaschak, Michael P.},
doi = {10.3758/BF03196313},
issn = {1069-9384},
journal = {Psychonomic Bulletin {\&} Review},
month = {sep},
number = {3},
pages = {558--565},
publisher = {Springer-Verlag},
title = {{Grounding language in action}},
volume = {9},
year = {2002}
}

@article{Madden2010,
abstract = {This article addresses issues in embodied sentence processing from a “cognitive neural systems” approach that combines analysis of the behavior in question, analysis of the known neurophysiological bases of this behavior, and the synthesis of a neuro-computational model of embodied sentence processing that can be applied to and tested in the context of human–robot cooperative interaction. We propose a Hybrid Comprehension Model that links compact propositional representations of sentences and discourse with their temporal unfolding in situated simulations, under the control of grammar. The starting point is a model of grammatical construction processing which specifies the neural mechanisms by which language is a structured inventory of mappings from sentence to meaning. This model is then “embodied” in a perceptual-motor system (robot) which allows it access to sentence-perceptual representation pairs, and interaction with the world providing the basis for language acquisition. We then introduce a “simulation” capability, such that the robot has an internal representation of its interaction with the world. The control of this simulator and the associated representations present a number of interesting “neuro-technical” issues. First, the “simulator” has been liberated from real-time. It can run without being connected to current sensory motor experience. Second, “simulations” appear to be represented at different levels of detail. Our paper provides a framework for beginning to address the questions: how does language and its grammar control these aspects of simulation, what are the neurophysiological bases, and how can this be demonstrated in an artificial yet embodied cognitive system.},
author = {Madden, Carol and Hoen, Michel and Dominey, Peter Ford},
doi = {10.1016/J.BANDL.2009.07.001},
issn = {0093-934X},
journal = {Brain and Language},
month = {mar},
number = {3},
pages = {180--188},
publisher = {Academic Press},
title = {{A cognitive neuroscience perspective on embodied language for human–robot cooperation}},
volume = {112},
year = {2010}
}

@article{Dominey2005,
author = {Dominey, Peter Ford},
doi = {10.1080/09540090500270714},
issn = {0954-0091},
journal = {Connection Science},
month = {sep},
number = {3-4},
pages = {289--306},
title = {{Emergence of grammatical constructions: evidence from simulation and grounded agent experiments}},
volume = {17},
year = {2005}
}


% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{Calandra2016,
  Title                    = {Bayesian Optimization for Learning Gaits under Uncertainty},
  Author                   = {Calandra, Roberto and Andr\'e Seyfarth and Peters, Jan and Marc P. Deisenroth},
  Journal                  = {Annals of Mathematics and Artificial Intelligence (AMAI)},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {5--23},
  Volume                   = {76},

  Doi                      = {10.1007/s10472-015-9463-9},
  ISSN                     = {1573-7470},
  Keywords                 = {Gait Optimization, Bayesian Optimization, Bipedal Locomotion, Optimization},
  Owner                    = {Roberto Calandra},
  Timestamp                = {2015.05.06}
}

@Article{tscl,
  author    = {Tambet Matiisen and
               Avital Oliver and
               Taco Cohen and
               John Schulman},
  title     = {Teacher-Student Curriculum Learning},
  journal   = {CoRR},
  volume    = {abs/1707.00183},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.00183},
  archivePrefix = {arXiv},
  eprint    = {1707.00183},
  timestamp = {Mon, 13 Aug 2018 16:48:57 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MatiisenOCS17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zpdes,
author = {Clement, Benjamin and Roy, Didier and Oudeyer, Pierre-Yves and Lopes, Manuel},
year = {2014},
month = {12},
pages = {},
title = {Developmental Learning for Intelligent Tutoring Systems},
journal = {IEEE ICDL-EPIROB 2014 - 4th Joint IEEE International Conference on Development and Learning and on Epigenetic Robotics},
doi = {10.1109/DEVLRN.2014.6983019}
}

@inproceedings{DBLP:conf/icml/HaarnojaZAL18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  pages     = {1856--1865},
  year      = {2018},
  crossref  = {DBLP:conf/icml/2018},
  url       = {http://proceedings.mlr.press/v80/haarnoja18b.html},
  timestamp = {Wed, 03 Apr 2019 18:17:30 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icml/HaarnojaZAL18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:journals/corr/LillicrapHPHETS15,
  author    = {Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title     = {Continuous control with deep reinforcement learning},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
  crossref  = {DBLP:conf/iclr/2016},
  url       = {http://arxiv.org/abs/1509.02971},
  timestamp = {Fri, 29 Mar 2019 10:35:07 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LillicrapHPHETS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{KAELBLING199899,
title = "Planning and acting in partially observable stochastic domains",
journal = "Artificial Intelligence",
volume = "101",
number = "1",
pages = "99 - 134",
year = "1998",
issn = "0004-3702",
doi = "https://doi.org/10.1016/S0004-3702(98)00023-X",
url = "http://www.sciencedirect.com/science/article/pii/S000437029800023X",
author = "Leslie Pack Kaelbling and Michael L. Littman and Anthony R. Cassandra",
keywords = "Planning, Uncertainty, Partially observable Markov decision processes",
abstract = "In this paper, we bring techniques from operations research to bear on the problem of choosing optimal actions in partially observable stochastic domains. We begin by introducing the theory of Markov decision processes (mdps) and partially observable MDPs (pomdps). We then outline a novel algorithm for solving pomdps off line and show how, in some cases, a finite-memory controller can be extracted from the solution to a POMDP. We conclude with a discussion of how our approach relates to previous work, the complexity of finding exact solutions to pomdps, and of some possibilities for finding approximate solutions."
}

@inproceedings{curious,
  author    = {C{\'{e}}dric Colas and
               Pierre{-}Yves Oudeyer and
               Olivier Sigaud and
               Pierre Fournier and
               Mohamed Chetouani},
  title     = {{CURIOUS:} Intrinsically Motivated Modular Multi-Goal Reinforcement
               Learning},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning,
               {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}},
  pages     = {1331--1340},
  year      = {2019},
  timestamp = {Tue, 11 Jun 2019 15:37:38 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icml/ColasOSFC19},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{goalgan,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018}
}


@Article{unicorn,
  author    = {Daniel J. Mankowitz and
               Augustin Z{\'{\i}}dek and
               Andr{\'{e}} Barreto and
               Dan Horgan and
               Matteo Hessel and
               John Quan and
               Junhyuk Oh and
               Hado van Hasselt and
               David Silver and
               Tom Schaul},
  title     = {Unicorn: Continual Learning with a Universal, Off-policy Agent},
  journal   = {CoRR},
  volume    = {abs/1802.08294},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.08294},
  archivePrefix = {arXiv},
  eprint    = {1802.08294},
  timestamp = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1802-08294},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{poet,
  author    = {Rui Wang and
               Joel Lehman and
               Jeff Clune and
               Kenneth O. Stanley},
  title     = {Paired Open-Ended Trailblazer {(POET):} Endlessly Generating Increasingly
               Complex and Diverse Learning Environments and Their Solutions},
  journal   = {CoRR},
  volume    = {abs/1901.01753},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.01753},
  archivePrefix = {arXiv},
  eprint    = {1901.01753},
  timestamp = {Thu, 31 Jan 2019 13:52:49 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1901-01753},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{riac,
  author    = {Adrien Baranes and
               Pierre{-}Yves Oudeyer},
  title     = {{R-IAC:} Robust Intrinsically Motivated Exploration and Active Learning},
  journal   = {{IEEE} Trans. Autonomous Mental Development},
  volume    = {1},
  number    = {3},
  pages     = {155--169},
  year      = {2009},
  url       = {https://doi.org/10.1109/TAMD.2009.2037513},
  doi       = {10.1109/TAMD.2009.2037513},
  timestamp = {Sat, 27 May 2017 14:23:02 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/tamd/BaranesO09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{nguyen2014socially,
  title={Socially guided intrinsic motivation for robot learning of motor skills},
  author={Nguyen, Mai and Oudeyer, Pierre-Yves},
  journal={Autonomous Robots},
  volume={36},
  number={3},
  pages={273--294},
  year={2014},
  publisher={Springer}
}

@article{rolf2013efficient,
  title={Efficient exploratory learning of inverse kinematics on a bionic elephant trunk},
  author={Rolf, Matthias and Steil, Jochen J},
  journal={IEEE transactions on neural networks and learning systems},
  volume={25},
  number={6},
  pages={1147--1160},
  year={2013},
  publisher={IEEE}
}

@article{lonini2013robust,
  title={Robust active binocular vision through intrinsically motivated learning},
  author={Lonini, Luca and Forestier, S{\'e}bastien and Teuli{\`e}re, C{\'e}line and Zhao, Yu and Shi, Bertram E and Triesch, Jochen},
  journal={Frontiers in neurorobotics},
  volume={7},
  pages={20},
  year={2013},
  publisher={Frontiers}
}

@article{saggriac,
  author    = {Adrien Baranes and
               Pierre{-}Yves Oudeyer},
  title     = {Active Learning of Inverse Models with Intrinsically Motivated Goal
               Exploration in Robots},
  journal   = {CoRR},
  volume    = {abs/1301.4862},
  year      = {2013},
  url       = {http://arxiv.org/abs/1301.4862},
  archivePrefix = {arXiv},
  eprint    = {1301.4862},
  timestamp = {Mon, 13 Aug 2018 16:47:28 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1301-4862},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{moulinfriergmm,
	Author = {Moulin-Frier, Cl{\'e}ment and Nguyen, Sao Mai and Oudeyer, Pierre-Yves},
	Date-Modified = {2014-08-15 15:49:29 +0100},
	Doi = {10.3389/fpsyg.2013.01006},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology (Cognitive Science)},
	Number = {1006},
	Title = {Self-Organization of Early Vocal Development in Infants and Machines: The Role of Intrinsic Motivation},
	Url = {http://www.frontiersin.org/cognitive_science/10.3389/fpsyg.2013.01006/abstract},
	Volume = {4},
	Year = {2014}}
	
	@article{kdtree,
  author    = {Jon Louis Bentley},
  title     = {Multidimensional Binary Search Trees Used for Associative Searching},
  journal   = {Commun. {ACM}},
  volume    = {18},
  number    = {9},
  pages     = {509--517},
  year      = {1975},
  url       = {http://doi.acm.org/10.1145/361002.361007},
  doi       = {10.1145/361002.361007},
  timestamp = {Wed, 14 Nov 2018 10:22:32 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/cacm/Bentley75},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@article{agentdesignha,
  author    = {David Ha},
  title     = {Reinforcement Learning for Improving Agent Design},
  journal   = {CoRR},
  volume    = {abs/1810.03779},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.03779},
  archivePrefix = {arXiv},
  eprint    = {1810.03779},
  timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-03779},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tscllike,
  author    = {Mysore, S., Platt, R., Saenko, K.},
  title     = {Reward-guided Curriculum for Robust Reinforcement Learning},
  year      = {2018}
}

@inproceedings{bengiocl,
  author    = {Yoshua Bengio and
               J{\'{e}}r{\^{o}}me Louradour and
               Ronan Collobert and
               Jason Weston},
  title     = {Curriculum learning},
  booktitle = {Proceedings of the 26th Annual International Conference on Machine
               Learning, {ICML} 2009, Montreal, Quebec, Canada, June 14-18, 2009},
  pages     = {41--48},
  year      = {2009},
  url       = {https://doi.org/10.1145/1553374.1553380},
  doi       = {10.1145/1553374.1553380},
  timestamp = {Wed, 14 Nov 2018 10:58:56 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/icml/BengioLCW09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{elman,
title = "Learning and development in neural networks: the importance of starting small",
journal = "Cognition",
volume = "48",
number = "1",
pages = "71 - 99",
year = "1993",
issn = "0010-0277",
doi = "https://doi.org/10.1016/0010-0277(93)90058-4",
url = "http://www.sciencedirect.com/science/article/pii/0010027793900584",
author = "Jeffrey L. Elman"
}

@article{taylortransfer,
 author = {Taylor, Matthew E. and Stone, Peter},
 title = {Transfer Learning for Reinforcement Learning Domains: A Survey},
 journal = {J. Mach. Learn. Res.},
 issue_date = {12/1/2009},
 volume = {10},
 month = dec,
 year = {2009},
 issn = {1532-4435},
 pages = {1633--1685},
 numpages = {53},
 url = {http://dl.acm.org/citation.cfm?id=1577069.1755839},
 acmid = {1755839},
 publisher = {JMLR.org},
} 
[download]

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in neural information processing systems},
  pages={5048--5058},
  year={2017}
}


@article{krueger,
title = "Flexible shaping: How learning in small steps helps",
journal = "Cognition",
volume = "110",
number = "3",
pages = "380 - 394",
year = "2009",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2008.11.014",
url = "http://www.sciencedirect.com/science/article/pii/S0010027708002850",
author = "Kai A. Krueger and Peter Dayan",
keywords = "PFC, Gating, Shaping, Sequence learning, Computational modeling"
}

@article{playgroundexp,
author = "P. Oudeyer and F. Kaplan and V. Hafner and A. Whyte",
title = "The playground experiment: Task-independent development of a curious robot",
journal = "Proceedings
of the AAAI Spring Symposium on Developmental Robotics",
pages = "42 - 47",
year = "2005"
}

@article{devrobbook,
author = {Blank, Douglas and Kumar, Deepak and Meeden, Lisa and Marshall, James},
year = {2003},
month = {12},
pages = {},
title = {Bringing up robot: Fundamental mechanisms for creating a self-motivated, self-organizing architecture},
journal = {Cybernetics & Systems},
doi = {10.1080/01969720590897107}
}
 
@inproceedings{lopes2012exploration,
  title={Exploration in model-based reinforcement learning by empirically estimating learning progress},
  author={Lopes, Manuel and Lang, Tobias and Toussaint, Marc and Oudeyer, Pierre-Yves},
  booktitle={Advances in neural information processing systems},
  pages={206--214},
  year={2012}
}

@inproceedings{kim2020active,
  title={Active world model learning with progress curiosity},
  author={Kim, Kuno and Sano, Megumi and De Freitas, Julian and Haber, Nick and Yamins, Daniel},
  booktitle={International Conference on Machine Learning},
  pages={5306--5315},
  year={2020},
  organization={PMLR}
}

@book{intrinsicbook ,
author = {E.L. Deci and M. Ryan},
title = {Intrinsic Motivation and self-determination in
human behavior},
publisher = {Plenum Press},
address = {New York},
year = "1985",
}

@inproceedings{strategicstudent,
  TITLE = {{The Strategic Student Approach for Life-Long Exploration and Learning}},
  AUTHOR = {Lopes, Manuel and Oudeyer, Pierre-Yves},
  URL = {https://hal.inria.fr/hal-00755216},
  BOOKTITLE = {{IEEE Conference on Development and Learning / EpiRob 2012}},
  ADDRESS = {San Diego, United States},
  YEAR = {2012},
  MONTH = Nov,
  PDF = {https://hal.inria.fr/hal-00755216/file/PID2563983.pdf},
  HAL_ID = {hal-00755216},
  HAL_VERSION = {v1},
}

@article{sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bic,
  added-at = {2009-08-24T15:07:31.000+0200},
  author = {Schwarz, G.},
  biburl = {https://www.bibsonomy.org/bibtex/215b8ffe9f50cb4fca87e30b578ac8f2e/neongod},
  interhash = {6b480223b0df6bd10504863cede240c5},
  intrahash = {15b8ffe9f50cb4fca87e30b578ac8f2e},
  journal = {The Annals of Statistics},
  keywords = {bayesian bic criterion information},
  pages = {461--464},
  timestamp = {2009-08-24T15:07:32.000+0200},
  title = {Estimating the dimension of a model},
  volume = 6,
  year = 1978
}

@Article{aic,
author="Bozdogan, Hamparsum",
title="Model selection and Akaike's Information Criterion (AIC): The general theory and its analytical extensions",
journal="Psychometrika",
year="1987",
month="Sep",
day="01",
volume="52",
number="3",
pages="345--370",
issn="1860-0980",
doi="10.1007/BF02294361",
url="https://doi.org/10.1007/BF02294361"
}

@inproceedings{malmo,
  author    = {Matthew Johnson and
               Katja Hofmann and
               Tim Hutton and
               David Bignell},
  title     = {The Malmo Platform for Artificial Intelligence Experimentation},
  booktitle = {Proceedings of the Twenty-Fifth International Joint Conference on
               Artificial Intelligence, {IJCAI} 2016, New York, NY, USA, 9-15 July
               2016},
  pages     = {4246--4247},
  year      = {2016},
  crossref  = {DBLP:conf/ijcai/2016},
  url       = {http://www.ijcai.org/Abstract/16/643},
  timestamp = {Fri, 15 Jul 2016 15:58:28 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/ijcai/JohnsonHHB16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@incollection{gmm,
title = {The Infinite Gaussian Mixture Model},
author = {Carl Edward Rasmussen},
booktitle = {Advances in Neural Information Processing Systems 12},
editor = {S. A. Solla and T. K. Leen and K. M\"{u}ller},
pages = {554--560},
year = {2000},
publisher = {MIT Press},
url = {http://papers.nips.cc/paper/1745-the-infinite-gaussian-mixture-model.pdf}
}

@ARTICLE{EMalgo,
    author = {A. P. Dempster and N. M. Laird and D. B. Rubin},
    title = {Maximum likelihood from incomplete data via the EM algorithm},
    journal = {JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SERIES B},
    year = {1977},
    volume = {39},
    number = {1},
    pages = {1--38}
}


@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}


@incollection{Vygotskii1978,
abstract = {Vygotsky, L. S. (1978). Mind in Society. The development of higher psychological processes. Cambridge, MA: Harvard University Press.},
author = {Vygotsky, L. S.},
booktitle = {Mind in Society},
chapter = {Tool and Symbol in Child Development},
doi = {10.2307/j.ctvjf9vz4.6},
isbn = {0674576292},
pages = {19--30},
publisher = {Harvard University Press},
title = {{Tool and Symbol in Child Development}},
year = {1978}
}

@article{fujimoto2018addressing,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, Dave},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{DBLP:journals/tnn/SuttonB98,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement Learning: An Introduction},
  journal   = {{IEEE} Trans. Neural Networks},
  volume    = {9},
  number    = {5},
  pages     = {1054--1054},
  year      = {1998},
  url       = {https://doi.org/10.1109/TNN.1998.712192},
  doi       = {10.1109/TNN.1998.712192},
  timestamp = {Sun, 28 May 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/tnn/SuttonB98},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}


@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}



@article{veeriah2018many,
  title={Many-Goals Reinforcement Learning},
  author={Veeriah, Vivek and Oh, Junhyuk and Singh, Satinder},
  journal={arXiv preprint arXiv:1806.09605},
  year={2018}
}

@article{mann1947test,
  title={On a test of whether one of two random variables is stochastically larger than the other},
  author={Mann, Henry B and Whitney, Donald R},
  journal={The annals of mathematical statistics},
  pages={50--60},
  year={1947},
  publisher={JSTOR}
}


@incollection{kaplan2004maximizing,
  title={Maximizing learning progress: an internal reward system for development},
  author={Kaplan, Fr{\'e}d{\'e}ric and Oudeyer, Pierre-Yves},
  booktitle={Embodied artificial intelligence},
  pages={259--270},
  year={2004},
  publisher={Springer}
}

@article{espeholt2018impala,
  title={IMPALA: Scalable distributed Deep-RL with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}


@article{mai2012active,
  title={Active choice of teachers, learning strategies and goals for a socially guided intrinsic motivation learner},
  author={Nguyen, Sao Mai and Oudeyer, Pierre-Yves},
  journal={Paladyn},
  volume={3},
  number={3},
  pages={136--146},
  year={2012},
  publisher={Springer}
}

@article{zhao2018energy,
  title={Energy-Based Hindsight Experience Prioritization},
  author={Zhao, Rui and Tresp, Volker},
  journal={arXiv preprint arXiv:1810.01363},
  year={2018}
}


@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}


@article{levy2018hierarchical,
  title={Hierarchical Reinforcement Learning with Hindsight},
  author={Levy, Andrew and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1805.08180},
  year={2018}
}


@article{hessel2018multi,
  title={Multi-task deep reinforcement learning with popart},
  author={Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  journal={arXiv preprint arXiv:1809.04474},
  year={2018}
}

@inproceedings{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4496--4506},
  year={2017}
}



@inproceedings{schmidhuber1991curious,
  title={Curious model-building control systems},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Neural Networks, 1991. 1991 IEEE International Joint Conference on},
  pages={1458--1463},
  year={1991},
  organization={IEEE}
}


@inproceedings{lopes2012strategic,
  title={The strategic student approach for life-long exploration and learning},
  author={Lopes, Manuel and Oudeyer, Pierre-Yves},
  booktitle={Development and Learning and Epigenetic Robotics (ICDL), 2012 IEEE International Conference on},
  pages={1--8},
  year={2012},
  organization={IEEE}
}

@article{vevcerik2017leveraging,
  title={Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards},
  author={Ve{\v{c}}er{\'\i}k, Matej and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
} 

@article{held2017automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Held, David and Geng, Xinyang and Florensa, Carlos and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1705.06366},
  year={2017}
}

@inproceedings{baranes2011interaction,
  title={The interaction of maturational constraints and intrinsic motivations in active motor development},
  author={Baranes, Adrien and Oudeyer, Pierre-Yves},
  booktitle={Development and Learning (ICDL), 2011 IEEE International Conference on},
  volume={2},
  pages={1--8},
  year={2011},
  organization={IEEE}
}



@article{schmidhuber2010formal,
  title={Formal theory of creativity, fun, and intrinsic motivation (1990--2010)},
  author={Schmidhuber, J{\"u}rgen},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={3},
  pages={230--247},
  year={2010},
  publisher={IEEE}
}


@article{mathys2011bayesian,
  title={A Bayesian foundation for individual learning under uncertainty},
  author={Mathys, Christoph and Daunizeau, Jean and Friston, Karl J and Stephan, Klaas Enno},
  journal={Frontiers in human neuroscience},
  volume={5},
  pages={39},
  year={2011},
  publisher={Frontiers}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@article{colas2018gep,
  title={{GEP-PG}: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms},
  author={Colas, C{\'e}dric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:1802.05054},
  year={2018}
}

@article{ther,
  title={Self-Educated Language Agent With Hindsight Experience Replay For Instruction Following},
  author={Cideron, Geoffrey and Seurin, Mathieu and Strub, Florian and Pietquin, Olivier},
  journal={arXiv preprint arXiv:1910.09451},
  year={2019}
}



@article{Bruner1991,
abstract = {Surely since the Enlightenment, if not before, the study of mind has centered principally on how man achieves a "true" knowledge of the world. Emphasis in this pursuit has varied, of course: empiricists have con- centrated on the mind's interplay with an external world of nature, hop- ing to find the key in the association of sensations and ideas, while rationalists have looked inward to the powers of mind itself for the princi- ples of right reason. The objective, in either case, has been to discover how we achieve "reality," that is to say, how we get a reliable fix on the world, a world that is, as it were, assumed to be immutable and, as it were, "there to be observed."},
author = {Bruner, Jerome},
doi = {10.1086/448619},
issn = {0093-1896},
journal = {Critical Inquiry},
mendeley-groups = {Psychology,Cognitive neuroscience},
month = {oct},
number = {1},
pages = {1--21},
publisher = {University of Chicago Press},
title = {{The Narrative Construction of Reality}},
url = {},
volume = {18},
year = {1991}
}
@article{settersolver,
author = {Racanière, Sébastien and Lampinen, Andrew and Santoro, Adam and Reichert, David and Firoiu, Vlad and Lillicrap, Timothy},
year = {2019},
title = {Automated curricula through setter-solver interactions},
journal={arXiv}
}

@inproceedings{hartikainen2019dynamical,
  title={Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery},
  author={Hartikainen, Kristian and Geng, Xinyang and Haarnoja, Tuomas and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{geppg,
  title={Gep-pg: Decoupling exploration and exploitation in deep reinforcement learning algorithms},
  author={Colas, C{\'e}dric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:1802.05054},
  year={2018}
}


@article{portelas2020automatic,
  title={Automatic Curriculum Learning For Deep RL: A Short Survey},
  author={Portelas, R{\'e}my and Colas, C{\'e}dric and Weng, Lilian and Hofmann, Katja and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:2003.04664},
  year={2020}
}


@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}


@article{eysenbach2018diversity,
  title={Diversity is all you need: Learning skills without a reward function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  journal={arXiv},
  year={2018}
}

@article{imagine,
  title={Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven Exploration},
  author={Colas, C\'edric and Karch, Tristan and Lair, Nicolas and Dussoux, Jean-Michel and Moulin-Frier, Cl\'ement and Ford Dominey, Peter and Oudeyer, Pierre-Yves},
  journal={arXiv},
  year={2020}
}


@book{Piaget2002,
abstract = {3rd ed. This book is for anyone who has ever wondered how a child develops language, thought, and knowledge. Before this classic appeared, little was known of the way children think. In 1923, however, Jean Piaget, the most important developmental psychologist of the twentieth century, took the psychological world by storm with The Language and Thought of the Child. Applying for the first time the insights of social psychology and psychoanalysis to the observation of children, he uncovered the ways in which a child actively constructs his or her understanding of the world through language. The book has since been a source of inspiration and guidance to generations of parents and teachers. While its conclusions remain contentious to this very day, few can deny the huge debt we owe to this pioneering work in our continuing attempts to understand the minds of the child -- publisher's description. The functions of language in two children of six -- Types and stages in the conversation of children between the ages of four and seven -- Understanding and verbal explanation between children of the same age between the years of six and eight -- Some peculiarities of verbal understanding in the child between the ages of nine and eleven -- The questions of a child of six -- The measure of ego-centric language in verbal communication between the adult and the child and in verbal exchanges between children.},
author = {Piaget, Jean},
isbn = {0415267501},
mendeley-groups = {Psychology,Cognitive neuroscience},
pages = {294},
publisher = {Routledge},
title = {{The language and thought of the child}},
year = {1926}
}

@book{Tomasello1999,
abstract = {"Many current theories of human cognition stress its biological roots, while others stress its cultural roots. Tomasello demonstrates that both of these perspectives are essential in creating a unified account of the evolution, history, and development of human cognition. He makes a powerful case that while human cognition is biologically based, this biological adaptation's key contribution is that it permits the flowering of the cultural-historical and ontogenetic processes that have actually made the varieties of human cognition what they are today."--Jacket. 1. A Puzzle and a Hypothesis; 2. Biological and Cultural Inheritance; 3. Joint Attention and Cultural Learning; 4. Linguistic Communication and Symbolic Representation; 5. Linguistic Constructions and Event Cognition; 6. Discourse and Representational Redescription; 7. Cultural Cognition; References; Index.},
author = {Tomasello, Michael},
publisher={Harvard University Press},
isbn = {9780674005822},
mendeley-groups = {Psychology,Cognitive neuroscience},
title = {{The cultural origins of human cognition}},
year = {1999}
}

@book{Chomsky1957,
abstract = {Noam Chomsky's first book on syntactic structures is one of the first serious attempts on the part of a linguist to construct within the tradition of scientific theory-construction a comprehensive theory of language which may be understood in the same sense that a chemical, biological theory is understood by experts in those fields. It is not a mere reorganization of the data into a new kind of library catalogue, nor another specualtive philosophy about the nature of man and language, but rather a rigorus explication of our intuitions about our language in terms of an overt axiom system, the theorems derivable from it, explicit results which may be compared with new data and other intuitions, all based plainly on an overt theory of the internal structure of languages; and it may well provide an opportunity for the application of explicity measures of simplicity to decide preference of one form over another form of grammar. Introduction --- The Independence of Grammar --- An Elementary Linguistic Theory --- Phrase Structure --- Limitations of Phrase Structure Description --- On the Goals of Linguistic Theory --- Some Transformations in English --- The Explanatory Power of Linguistic Theory --- Syntax and Semantics --- Summary --- Appendix I: Notations and Terminology --- Appendix II: Examples of English Phrase Structure and Transformational Rules.},
author = {Chomsky, Noam.},
isbn = {9789027933850},
mendeley-groups = {Psychology,Cognitive neuroscience},
publisher = {Mouton},
title = {{Syntactic structures}},
year = {1957}
}
